import torch
import os
import numpy as np
import matplotlib.pyplot as plt
from datasets import load_dataset
from sklearn.metrics import accuracy_score
from transformers import (
    ViTImageProcessor, 
    ViTForImageClassification, 
    TrainingArguments, 
    Trainer, 
    DefaultDataCollator
)

# --- 1. AYARLAR ---
# KopyaladÄ±ÄŸÄ±n tam yolu buraya tÄ±rnak iÃ§inde yapÄ±ÅŸtÄ±rdÄ±k
DATASET_PATH = r"/Users/elifbeyzabeyaz/Desktop/sektorkampuste/flowers" 
MODEL_NAME = "google/vit-base-patch16-224"
OUTPUT_DIR = "./flowers_vit_model_cikti"
EPOCHS = 10
BATCH_SIZE = 16 

# --- 2. GPU (MPS) KONTROLÃœ ---
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("\nMac GPU (MPS) Tespit Edildi. EÄŸitim GPU Ã¼zerinde yapÄ±lacak.")
else:
    device = torch.device("cpu")
    print("\nMPS bulunamadÄ±, iÅŸlemler CPU Ã¼zerinden devam edecek.")

# --- 3. VERÄ° SETÄ°NÄ° YÃœKLEME (KRÄ°TÄ°K DÃœZELTME) ---
print(f"ğŸ“‚ Veri seti okunuyor: {DATASET_PATH}")

# 'split="train"' parametresi EmptyDatasetError hatasÄ±nÄ± Ã§Ã¶zer.
try:
    ds = load_dataset("imagefolder", data_dir=DATASET_PATH, split="train")
    # Veriyi %80 EÄŸitim, %20 Test olarak bÃ¶lÃ¼yoruz
    ds = ds.train_test_split(test_size=0.2, seed=42)
except Exception as e:
    print(f"âŒ HATA: Veri yÃ¼klenemedi. KlasÃ¶r yapÄ±sÄ±nÄ± kontrol edin.\nDetay: {e}")
    exit()

labels = ds['train'].features['label'].names
label2id = {label: str(i) for i, label in enumerate(labels)}
id2label = {str(i): label for i, label in enumerate(labels)}

print(f"SÄ±nÄ±flar: {labels}")

# --- 4. Ã–N Ä°ÅLEME ---
processor = ViTImageProcessor.from_pretrained(MODEL_NAME)

def transform(example_batch):
    # 'imagefolder' ile yÃ¼klenen verilerde resim sÃ¼tunu 'image' adÄ±nÄ± alÄ±r.
    inputs = processor([x.convert("RGB") for x in example_batch['image']], return_tensors='pt')
    inputs['labels'] = example_batch['label']
    return inputs

prepared_ds = ds.with_transform(transform)

# --- 5. MODELÄ° HAZIRLAMA ---
model = ViTForImageClassification.from_pretrained(
    MODEL_NAME,
    num_labels=len(labels),
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True
)
model.to(device)

# --- 6. METRÄ°K ---
def compute_metrics(p):
    return {"accuracy": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1))}

# --- 7. EÄÄ°TÄ°M AYARLARI ---
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=EPOCHS,
    learning_rate=2e-5,
    weight_decay=0.01,
    remove_unused_columns=False, # Transform kullandÄ±ÄŸÄ±mÄ±z iÃ§in False kalmalÄ±
    eval_strategy="epoch",       
    save_strategy="epoch",
    load_best_model_at_end=True,
    fp16=False,                  # Mac MPS'de kararlÄ±lÄ±k iÃ§in False (Ã–nemli)
    dataloader_num_workers=0,    # Mac'te MPS Ã§akÄ±ÅŸmasÄ±nÄ± Ã¶nlemek iÃ§in 0
    logging_steps=10,
    report_to="none"
)

# --- 8. TRAINER ---
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=prepared_ds["train"],
    eval_dataset=prepared_ds["test"],
    data_collator=DefaultDataCollator(),
    processing_class=processor, 
    compute_metrics=compute_metrics,
)

print("\n EÄŸitim BaÅŸlÄ±yor...")
trainer.train()

# --- 9. KAYIT ---
trainer.save_model(OUTPUT_DIR)
processor.save_pretrained(OUTPUT_DIR)
print(f"\nModel baÅŸarÄ±yla kaydedildi: {OUTPUT_DIR}")

# --- 10. NÄ°HAÄ° DEÄERLENDÄ°RME ---
print("\nTest Seti Ãœzerindeki Nihai DeÄŸerlendirme SonuÃ§larÄ±")
metrics = trainer.evaluate()

for key, value in metrics.items():
    print(f"{key}: {value:.4f}")